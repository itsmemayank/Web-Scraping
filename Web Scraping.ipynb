{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>1 - Installing bs4 module</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\mayan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\mayan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\mayan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>2 - Installing requests module</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\mayan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\mayan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\mayan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mayan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\mayan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send a request and receive the information from https://www.google.com\n",
    "response = requests.get(\"https://www.google.com\")\n",
    "\n",
    "# printing the response\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Date': 'Fri, 04 Dec 2020 14:43:26 GMT', 'Expires': '-1', 'Cache-Control': 'private, max-age=0', 'Content-Type': 'text/html; charset=ISO-8859-1', 'P3P': 'CP=\"This is not a P3P policy! See g.co/p3phelp for more info.\"', 'Content-Encoding': 'gzip', 'Server': 'gws', 'X-XSS-Protection': '0', 'X-Frame-Options': 'SAMEORIGIN', 'Set-Cookie': '1P_JAR=2020-12-04-14; expires=Sun, 03-Jan-2021 14:43:26 GMT; path=/; domain=.google.com; Secure, NID=204=YR4aYsZGVOuEFMDeyzr_PwPGRdmaDExgmpl7IIHXzdyV4--SuRVeXyJbitl3yr06aZGR3S1-7nI-VL8iJZPMJK0B9Xza5SaRev5Hx_ihOlFTlXAzz5Uf4kA3t71xAiMCtVVTDq-t_VgdggSPjZlO8o9QUTG4T3fhFRt9HwRxMGE; expires=Sat, 05-Jun-2021 14:43:26 GMT; path=/; domain=.google.com; HttpOnly', 'Alt-Svc': 'h3-29=\":443\"; ma=2592000,h3-T051=\":443\"; ma=2592000,h3-Q050=\":443\"; ma=2592000,h3-Q046=\":443\"; ma=2592000,h3-Q043=\":443\"; ma=2592000,quic=\":443\"; ma=2592000; v=\"46,43\"', 'Transfer-Encoding': 'chunked'}\n"
     ]
    }
   ],
   "source": [
    "print(response.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date \t\t Fri, 04 Dec 2020 14:43:26 GMT\n",
      "Expires \t\t -1\n",
      "Cache-Control \t\t private, max-age=0\n",
      "Content-Type \t\t text/html; charset=ISO-8859-1\n",
      "P3P \t\t CP=\"This is not a P3P policy! See g.co/p3phelp for more info.\"\n",
      "Content-Encoding \t\t gzip\n",
      "Server \t\t gws\n",
      "X-XSS-Protection \t\t 0\n",
      "X-Frame-Options \t\t SAMEORIGIN\n",
      "Set-Cookie \t\t 1P_JAR=2020-12-04-14; expires=Sun, 03-Jan-2021 14:43:26 GMT; path=/; domain=.google.com; Secure, NID=204=YR4aYsZGVOuEFMDeyzr_PwPGRdmaDExgmpl7IIHXzdyV4--SuRVeXyJbitl3yr06aZGR3S1-7nI-VL8iJZPMJK0B9Xza5SaRev5Hx_ihOlFTlXAzz5Uf4kA3t71xAiMCtVVTDq-t_VgdggSPjZlO8o9QUTG4T3fhFRt9HwRxMGE; expires=Sat, 05-Jun-2021 14:43:26 GMT; path=/; domain=.google.com; HttpOnly\n",
      "Alt-Svc \t\t h3-29=\":443\"; ma=2592000,h3-T051=\":443\"; ma=2592000,h3-Q050=\":443\"; ma=2592000,h3-Q046=\":443\"; ma=2592000,h3-Q043=\":443\"; ma=2592000,quic=\":443\"; ma=2592000; v=\"46,43\"\n",
      "Transfer-Encoding \t\t chunked\n"
     ]
    }
   ],
   "source": [
    "for key, value in response.headers.items():\n",
    "    print(key, '\\t\\t', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# Status of Request\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>3 - Setup User Agent</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fake_useragent in c:\\users\\mayan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (0.1.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install fake_useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import UserAgent from the fake_useragent module\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "# create an instance of the 'UserAgent' class\n",
    "obj = UserAgent()\n",
    "\n",
    "# create a dictionary with key 'user-agent' and value 'obj.chrome'\n",
    "header = {'user-agent': obj.chrome}\n",
    "\n",
    "# send request by passing 'header' to the 'headers' parameter in 'get' method\n",
    "r = requests.get('https://google.com', headers=header)\n",
    "\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>4 - BeautifulSoup: Prettify Content</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import requests\n",
    "\n",
    "# importing the beautifulsoup module\n",
    "import bs4\n",
    "\n",
    "# send a request and receive the information from https://www.google.com\n",
    "response = requests.get(\"https://www.google.com\")\n",
    "\n",
    "# creating BeautifulSoup object\n",
    "soup = bs4.BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# using 'prettify' method to print the content\n",
    "print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>5 - BeautifulSoup: Accessing HTML Tags</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import requests\n",
    "\n",
    "# importing the beautifulsoup module\n",
    "import bs4\n",
    "\n",
    "# send a request and receive the information from https://www.google.com\n",
    "response = requests.get(\"https://www.google.com\")\n",
    "\n",
    "# creating BeautifulSoup object\n",
    "soup = bs4.BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# getting 'title' tag from the google BeautifulSoup -> 'soup'\n",
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>6 - BeautifulSoup: contents method</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = soup.body\n",
    "\n",
    "# getting all the children of 'body' using 'contents'\n",
    "content_list = body.contents\n",
    "\n",
    "# printing all the children using for loop\n",
    "for tag in content_list:\n",
    "    if tag != \"\\n\":\n",
    "        print(tag)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>7 - BeautifulSoup: children method</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = soup.body\n",
    "\n",
    "## we can also convert iterator into list using the 'list(iterator)'\n",
    "for tag in body.children:\n",
    "    if tag != \"\\n\":\n",
    "        print(tag)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>8 - BeautifulSoup: descendants method</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = soup.body\n",
    "\n",
    "## we can also convert iterator into list using the 'list(iterator)'\n",
    "for tag in body.descendants:\n",
    "    if tag != \"\\n\":\n",
    "        print(tag)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>9 - BeautifulSoup: parent method</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html\n"
     ]
    }
   ],
   "source": [
    "body = soup.body\n",
    "\n",
    "# getting parent of 'body'\n",
    "body_parent = body.parent\n",
    "\n",
    "\n",
    "# you have to use 'name' method to print the name of the tag\n",
    "# printing the name of the parent using 'name' method\n",
    "print(body_parent.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>10 - BeautifulSoup: find_all method</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p style=\"font-size:8pt;color:#70757a\">© 2020 - <a href=\"/intl/en/policies/privacy/\">Privacy</a> - <a href=\"/intl/en/policies/terms/\">Terms</a></p>]\n"
     ]
    }
   ],
   "source": [
    "# finding all p tags\n",
    "p_tags = soup.find_all(\"p\")     \n",
    "print(p_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>11 - BeautifulSoup: find method</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p style=\"font-size:8pt;color:#70757a\">© 2020 - <a href=\"/intl/en/policies/privacy/\">Privacy</a> - <a href=\"/intl/en/policies/terms/\">Terms</a></p>\n",
      "© 2020 - Privacy - Terms\n"
     ]
    }
   ],
   "source": [
    "p_tag = soup.find(\"p\")\n",
    "\n",
    "print(p_tag)\n",
    "print(p_tag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>12 - Writing Data to CSV File</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing bs4, requests, fake_useragent and csv modules\n",
    "import bs4\n",
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "import csv\n",
    "\n",
    "# initializing the UserAgent object\n",
    "user_agent = UserAgent()\n",
    "url = \"https://www.consumerreports.org/cro/a-to-z-index/products/index.htm\"\n",
    "\n",
    "# getting the reponse from the page using get method of requests module\n",
    "page = requests.get(url, headers={\"user-agent\": user_agent.chrome})\n",
    "\n",
    "# storing the content of the page in a variable\n",
    "html = page.content\n",
    "\n",
    "# creating BeautifulSoup object\n",
    "soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# div tags with crux-body-copy class\n",
    "div_class = \"crux-body-copy\"\n",
    "\n",
    "# getting all the divs with class 'crux-body-copy'\n",
    "div_tags = soup.find_all(\"div\", class_=\"div_class\")\n",
    "\n",
    "# then we open a csv file in append mode\n",
    "with open(\"product_data.csv\", \"a\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    \n",
    "    # extracting the names and links from the div tags\n",
    "    for tag in div_tags:\n",
    "        name = tag.a.text.strip()\n",
    "        link = tag.a['href']\n",
    "        ## now we will write data to the file\n",
    "        writer.writerow([name, link])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
